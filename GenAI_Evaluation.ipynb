{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkqG9qXZvFU2"
      },
      "source": [
        "# GenAI course - Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW7AzWBZvJus"
      },
      "source": [
        "## Use pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgsXZBs_vOj0"
      },
      "source": [
        "Select a specific task involving image or text generation: image transformation, translation, summarisation, Q&A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39p_RqjVva0w"
      },
      "source": [
        "Find a dataset with annotated data corresponding to your selected task and load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KyzxBJn0v-qI"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"EdinburghNLP/xsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'document': 'The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we\\'re neglected or forgotten,\" she said.\\n\"That may not be true but it is perhaps my perspective over the last few days.\\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\\nThe Labour Party\\'s deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.', 'summary': 'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.', 'id': '35232142'}\n"
          ]
        }
      ],
      "source": [
        "print((dataset['train'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDOFuMS9wzD_"
      },
      "source": [
        "Divide the dataset into a train and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hbQHGRXBw20r"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 204045\n",
            "Test size: 11334\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3CSPEoRv_IP"
      },
      "source": [
        "Find a pre-trained model on the hugging face hub suitable for the selected task and load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bOpB9pfxwMcc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: True\n",
            "Device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Using GPU:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"Falconsai/text_summarization\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer , device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFew9qLiwM06"
      },
      "source": [
        "Select the appropriate metrics to evaluate the considered task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "==> I'll be choosing ROUGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul2nZekwwYKK"
      },
      "source": [
        "Use the selected metrics to evalute the model on your test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "42lphqdMwYa1"
      },
      "outputs": [],
      "source": [
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "rouge = load('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:17<00:00, 17.08s/it]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for i in tqdm(range(0, len(test_dataset[:11333]), batch_size)):\n",
        "    batch = test_dataset[i: i + batch_size]\n",
        "    inputs = batch[\"document\"]\n",
        "    refs = batch[\"summary\"]\n",
        "\n",
        "    #summarizing\n",
        "    results = summarizer(\n",
        "        inputs,\n",
        "        max_length=60,\n",
        "        min_length=10,\n",
        "        do_sample=False,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    #results collection\n",
        "    batch_preds = [res[\"summary_text\"] for res in results]\n",
        "    predictions.extend(batch_preds)\n",
        "    references.extend(refs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_preds = [res[\"summary_text\"] for res in results]\n",
        "predictions.extend(batch_preds)\n",
        "references.extend(refs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "seeing some summary generation examples:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**Article #1**\n",
            "\n",
            " Predicted Summary:\n",
            "Prison Link Cymru said some ex-offenders were living rough for up to a year . The Welsh Government said more people than ever were getting help to address housing problems . Changes to the Housing Act in Wales removed the right for prison leavers to be given\n",
            "\n",
            " Reference Summary:\n",
            "There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "**Article #2**\n",
            "\n",
            " Predicted Summary:\n",
            "a 26-year-old man appeared at Edinburgh Sheriff Court on Thursday . Detectives said three firearms, ammunition and a five-figure sum of money were recovered .\n",
            "\n",
            " Reference Summary:\n",
            "A man has appeared in court after firearms, ammunition and cash were seized by police in Edinburgh.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "**Article #3**\n",
            "\n",
            " Predicted Summary:\n",
            "Jordan Hill, Brittany Covington and Tesfaye Cooper appear in court . The four have been charged with hate crimes and aggravated kidnapping and battery . An online fundraiser for their victim has collected $51,000 (£42,500)\n",
            "\n",
            " Reference Summary:\n",
            "Four people accused of kidnapping and torturing a mentally disabled man in a \"racially motivated\" attack streamed on Facebook have been denied bail.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    print(f\"\\n**Article #{i+1}**\")\n",
        "    print(f\"\\n Predicted Summary:\\n{predictions[i]}\")\n",
        "    print(f\"\\n Reference Summary:\\n{references[i]}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#rouge evaluation with stemmer\n",
        "results = rouge.compute(predictions=predictions, references=references, use_stemmer=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE Evaluation Results with stemmer:\n",
            "\n",
            "ROUGE1: 0.2203514837155019\n",
            "ROUGE2: 0.04524804536021169\n",
            "ROUGEL: 0.14859661051613854\n",
            "ROUGELSUM: 0.1483190708967212\n"
          ]
        }
      ],
      "source": [
        "print(\"ROUGE Evaluation Results with stemmer:\\n\")\n",
        "for metric, score in results.items():\n",
        "    print(f\"{metric.upper()}: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "#rouge evaluation WITHOUT stemmer\n",
        "results = rouge.compute(predictions=predictions, references=references, use_stemmer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE Evaluation Results without stemmer:\n",
            "\n",
            "ROUGE1: 0.20796872560730545\n",
            "ROUGE2: 0.0430749737115319\n",
            "ROUGEL: 0.14176782992317571\n",
            "ROUGELSUM: 0.14136828931767265\n"
          ]
        }
      ],
      "source": [
        "print(\"ROUGE Evaluation Results without stemmer:\\n\")\n",
        "for metric, score in results.items():\n",
        "    print(f\"{metric.upper()}: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnOdJij_wldq"
      },
      "source": [
        "Comment the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Before Fine-tuning</th>\n",
              "      <th>After Fine-tuning</th>\n",
              "      <th>Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ROUGE1</th>\n",
              "      <td>0.2205</td>\n",
              "      <td>0.2927</td>\n",
              "      <td>0.0722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROUGE2</th>\n",
              "      <td>0.0452</td>\n",
              "      <td>0.0819</td>\n",
              "      <td>0.0367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROUGEL</th>\n",
              "      <td>0.1486</td>\n",
              "      <td>0.2263</td>\n",
              "      <td>0.0777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Before Fine-tuning  After Fine-tuning  Change\n",
              "ROUGE1              0.2205             0.2927  0.0722\n",
              "ROUGE2              0.0452             0.0819  0.0367\n",
              "ROUGEL              0.1486             0.2263  0.0777"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ROUGE scores before and after fine-tuning\n",
        "rouge_before = {\n",
        "    \"ROUGE1\": 0.2205,\n",
        "    \"ROUGE2\": 0.0452,\n",
        "    \"ROUGEL\": 0.1486\n",
        "}\n",
        "\n",
        "rouge_after = {\n",
        "    \"ROUGE1\": 0.2927,\n",
        "    \"ROUGE2\": 0.0819,\n",
        "    \"ROUGEL\": 0.2263\n",
        "}\n",
        "\n",
        "# Build table\n",
        "df = pd.DataFrame({\n",
        "    \"Before Fine-tuning\": rouge_before,\n",
        "    \"After Fine-tuning\": rouge_after,\n",
        "})\n",
        "\n",
        "# Add column for change\n",
        "df[\"Change\"] = df[\"After Fine-tuning\"] - df[\"Before Fine-tuning\"]\n",
        "df = df.round(4)  # Optional: round for readability\n",
        "\n",
        "# Display the table\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7auRf5LwnfZ"
      },
      "source": [
        "## Model fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsbmBaCww8DA"
      },
      "source": [
        "Use the train set to fine-tune the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Xq3ZH339wpMy"
      },
      "outputs": [],
      "source": [
        "#the tokenization function\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"document\"]\n",
        "    targets = examples[\"summary\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=60, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "subset_train = train_dataset.select(range(2000))\n",
        "subset_test = test_dataset.select(range(500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba0c8df1425f4144a67ab1a36f8bb370",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\asmag\\OneDrive\\Documents\\GENAI COURSE_EVALUATION\\gen_ai\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3062ae339974f349a0325e96135827b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train = subset_train.map(preprocess_function, batched=True)\n",
        "tokenized_test = subset_test.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIZPTInDxC8g"
      },
      "source": [
        "Use the selected metrics to evalute the fine-tuned model on your test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "s6LWj5lBxG_1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\asmag\\OneDrive\\Documents\\GENAI COURSE_EVALUATION\\gen_ai\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#config train\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./finetuned_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    num_train_epochs=3,  # Use 1 epoch for a quick run, increase for better results\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if on GPU\n",
        "    predict_with_generate=True,\n",
        "    logging_dir='./logs',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\asmag\\AppData\\Local\\Temp\\ipykernel_10440\\3650973091.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "#defining the trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 03:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.696500</td>\n",
              "      <td>2.524773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.664600</td>\n",
              "      <td>2.525098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.648500</td>\n",
              "      <td>2.525505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=2.6698451334635416, metrics={'train_runtime': 185.3774, 'train_samples_per_second': 32.366, 'train_steps_per_second': 8.092, 'total_flos': 789839950381056.0, 'train_loss': 2.6698451334635416, 'epoch': 3.0})"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXEUa7odxHRJ"
      },
      "source": [
        "Comment the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = [example[\"document\"] for example in subset_test]\n",
        "references = [example[\"summary\"] for example in subset_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for doc in inputs:\n",
        "    output = tokenizer(doc, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
        "    summary_ids = model.generate(**output, max_length=60, min_length=10)\n",
        "    pred = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    predictions.append(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE Evaluation After Fine-tuning:\n",
            "\n",
            "ROUGE1: 0.2927370305886142\n",
            "ROUGE2: 0.08188269800878917\n",
            "ROUGEL: 0.2263433231636263\n",
            "ROUGELSUM: 0.22617259846394355\n"
          ]
        }
      ],
      "source": [
        "#evaluating with rouge\n",
        "results = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
        "\n",
        "print(\"ROUGE Evaluation After Fine-tuning:\\n\")\n",
        "for metric, score in results.items():\n",
        "    print(f\"{metric.upper()}: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjxu4ZkixJWi"
      },
      "source": [
        "## To go further"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Von81CKxV7l"
      },
      "source": [
        "Explore how to implement a model from scrath and train it on your train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBS8UpIMxbv-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiqfFtZ3xcEB"
      },
      "source": [
        "Use the selected metrics to evalute the model trained from scratch on your test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEbHH6mIxjm2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx08v21SxlIB"
      },
      "source": [
        "Comment the results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gen_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
